{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "from transliterate import translit\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset informations\n",
    "\n",
    "https://hplt-project.org/datasets/v2.0 \\\n",
    "https://oscar-project.org/ \\\n",
    "https://huggingface.co/datasets/jerteh/SrpKorNews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hplt_dataset = load_dataset(\"HPLT/HPLT2.0_cleaned\", \"srp_Cyrl\", cache_dir=\"/data\", streaming=True, split=\"train\") \n",
    "oscar_dataset = load_dataset(\"oscar-corpus/OSCAR-2201\", \"sr\", cache_dir=\"/data\", trust_remote_code=True, streaming=True, split=\"train\")\n",
    "srpkor_dataset = load_dataset(\"jerteh/SrpKorNews\", cache_dir=\"/data\", streaming=True, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for hplt and oscar\n",
    "def filter_cyrillic_text(text, min_length=20):\n",
    "    '''\n",
    "    Filters input text by removing lines that:\n",
    "    - Contain fewer than 2 Cyrillic words\n",
    "    - Are shorter than the specified minimum length\n",
    "    - Contain bracketed numbers (e.g., [1], [23])\n",
    "    \n",
    "    Also removes leading non-alphabetic characters such as digits and special characters from each valid line.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input multi-line text.\n",
    "        min_length (int): The minimum length a line must have to be kept. Default is 20.\n",
    "    \n",
    "    Returns:\n",
    "        str: The cleaned text with filtered lines joined by newline characters.\n",
    "    '''\n",
    "    cyrillic_regex = re.compile('[\\u0400-\\u04FF]+')\n",
    "    lines = text.splitlines()\n",
    "    brackets_regex = re.compile(r'\\[\\d+\\]')\n",
    "\n",
    "    filtered_lines = [\n",
    "        brackets_regex.sub(\"\", line).lstrip(\"1234567890;#&:\").strip()\n",
    "        for line in lines\n",
    "        if len(line) >= min_length and len(re.findall(cyrillic_regex, line)) >= 2\n",
    "    ]\n",
    "\n",
    "    return \"\\n\".join(filtered_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for srpkornews\n",
    "def extract_and_transliterate_text(text, min_length=20):\n",
    "    '''\n",
    "    Parses and extracts visible text from HTML, then transliterates each sentence from Serbian Cyrillic to Latin.\n",
    "    It also:\n",
    "    - Removes bracketed number patterns (e.g., [1], [23])\n",
    "    - Skips lines shorter than the minimum length\n",
    "    - Removes leading digits and special characters from each line\n",
    "\n",
    "    Parameters:\n",
    "        text (str): HTML content as a string.\n",
    "        min_length (int): Minimum length a sentence must have to be included. Default is 20.\n",
    "    \n",
    "    Returns:\n",
    "        str: Transliterated and cleaned text with sentences joined by newlines.\n",
    "    '''\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    parsed_text = soup.get_text(separator=\". \", strip=True)\n",
    "    lines = re.findall(r'[^.]+\\.?', parsed_text)\n",
    "\n",
    "    brackets_regex = re.compile(r'\\[\\d+\\]')\n",
    "    filtered_lines = [\n",
    "        translit(brackets_regex.sub(\"\", line).lstrip(\"1234567890;#&:\").strip(), \"sr\")\n",
    "        for line in lines\n",
    "        if len(line) >= min_length\n",
    "    ]\n",
    "\n",
    "    return \"\\n\".join(filtered_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_hplt = hplt_dataset.map(lambda x: {\"text\": filter_cyrillic_text(x[\"text\"])})\n",
    "processed_oscar = oscar_dataset.map(lambda x: {\"text\": filter_cyrillic_text(x[\"text\"])})\n",
    "processed_srpkor = srpkor_dataset.map(lambda x: {\"text\": extract_and_transliterate_text(x[\"text\"])})\n",
    "\n",
    "processed_datasets = [processed_hplt, processed_oscar, processed_srpkor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_jsonl = \"concatenated_dataset.jsonl\"\n",
    "with open(output_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "    for ds in processed_datasets:\n",
    "        for example in tqdm(ds):\n",
    "            json_line = json.dumps({\"text\": example[\"text\"]})\n",
    "            f.write(json_line + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
